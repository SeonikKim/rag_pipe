#!/usr/bin/env python3
"""
â‘¦ ìµœì¢… JSON ìƒì„± (BGE-m3-ko ìµœì í™”)
ì…ë ¥: step6_llm/llm_selected.json
ì²˜ë¦¬: BGE-m3-ko ì„ë² ë”© ëª¨ë¸ì— ìµœì í™”ëœ JSON êµ¬ì¡° ìƒì„±
ì¶œë ¥: final_outputs/doc1_final.json, final_outputs/doc1_bge_optimized.json
"""

import json
from pathlib import Path
from datetime import datetime
import sys
sys.path.append('/home/cywell/project5')
from bge_m3_ko_optimized_schema import create_bge_optimized_json
from context_aware_schema import create_context_aware_json, create_bge_optimized_context_groups

# ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
CURRENT_SESSION_DIR = None

def clean_final_text(text):
    """ìµœì¢… í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text:
        return ""
    
    # ì—°ì† ê³µë°± ì •ë¦¬
    import re
    text = re.sub(r'\s+', ' ', text)
    
    # ë¬¸ì¥ ë¶€í˜¸ ì •ë¦¬
    text = re.sub(r'\s*([.!?])\s*', r'\1 ', text)
    text = re.sub(r'\s*([,;:])\s*', r'\1 ', text)
    
    # ê´„í˜¸ ì •ë¦¬
    text = re.sub(r'\(\s+', '(', text)
    text = re.sub(r'\s+\)', ')', text)
    
    # ë ê³µë°± ì œê±°
    text = text.strip()
    
    # ë§ˆì§€ë§‰ì— ë§ˆì¹¨í‘œê°€ ì—†ìœ¼ë©´ ì¶”ê°€
    if text and not text.endswith(('.', '!', '?')):
        # í•œêµ­ì–´ ì¢…ê²°ì–´ë¯¸ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
        if text.endswith(('ë‹¤', 'ìš”', 'ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ì„¸ìš”', 'ì£ ')):
            text += '.'
    
    return text

def create_final_json(data):
    """ìµœì¢… JSON êµ¬ì¡° ìƒì„±"""
    sections = data.get('sections', [])
    metadata = data.get('metadata', {})
    
    # ë¬¸ì„œ ID ê²°ì •
    document_id = data.get('document_id', 'unknown')
    if document_id == 'unknown':
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œ ì‹œë„
        source_pdf = metadata.get('source_pdf', '')
        if source_pdf:
            document_id = Path(source_pdf).stem
        else:
            document_id = f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # ì„¹ì…˜ ì²˜ë¦¬
    final_sections = []
    
    for section in sections:
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        text_combined = clean_final_text(section.get('text_combined', ''))
        
        # ë¹ˆ ì„¹ì…˜ ì œì™¸
        if not text_combined or len(text_combined.strip()) < 10:
            continue
        
        final_section = {
            "id": section.get('id', f"section_{len(final_sections)+1:03d}"),
            "title": section.get('title', '').strip(),
            "category": section.get('category', ''),
            "pages": sorted(section.get('pages', [])),
            "text_combined": text_combined
        }
        
        final_sections.append(final_section)
    
    # íŒŒì´í”„ë¼ì¸ ì •ë³´ êµ¬ì„±
    pipeline_steps = [
        "DotsOCR 1ì°¨",
        "2ì°¨ OCR(ê³ ì • ì˜µì…˜: Gaussian 5Ã—5 â†’ Unsharp r=1.3, p=150 â†’ ì—…ìŠ¤ì¼€ì¼ Ã—2.8)",
        "í˜•íƒœì†Œ êµì •(Kiwi)",
        "ë¬¸ë§¥ êµì •(LLM)",
        "ì„¹ì…˜ ë³‘í•©(BeautifulSoup4)"
    ]
    
    # ìµœì¢… JSON êµ¬ì¡°
    final_json = {
        "document_id": document_id,
        "sections": final_sections,
        "metadata": {
            "source_pdf": metadata.get('source_pdf', f"pdf_in/{document_id}.pdf"),
            "pipeline": pipeline_steps,
            "timestamp": datetime.now().isoformat(),
            "total_sections": len(final_sections),
            "processing_stats": {
                "kiwi_available": metadata.get('kiwi_available', False),
                "llm_model": metadata.get('llm_model', 'EEVE-Korean-Instruct-2.8B-v1.0'),
                "pipeline_stage": "ìµœì¢… ì™„ë£Œ"
            }
        }
    }
    
    return final_json

def validate_final_json(final_json):
    """ìµœì¢… JSON ê²€ì¦"""
    issues = []
    
    # í•„ìˆ˜ í•„ë“œ í™•ì¸
    if not final_json.get('document_id'):
        issues.append("document_idê°€ ì—†ìŠµë‹ˆë‹¤")
    
    if not final_json.get('sections'):
        issues.append("sectionsê°€ ì—†ìŠµë‹ˆë‹¤")
    
    # ì„¹ì…˜ ê²€ì¦
    sections = final_json.get('sections', [])
    for i, section in enumerate(sections):
        if not section.get('text_combined'):
            issues.append(f"ì„¹ì…˜ {i+1}: text_combinedê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        if not section.get('id'):
            issues.append(f"ì„¹ì…˜ {i+1}: idê°€ ì—†ìŠµë‹ˆë‹¤")
    
    return issues

def generate_summary(final_json):
    """ìµœì¢… ê²°ê³¼ ìš”ì•½"""
    sections = final_json.get('sections', [])
    
    total_chars = sum(len(s.get('text_combined', '')) for s in sections)
    total_pages = set()
    
    for section in sections:
        total_pages.update(section.get('pages', []))
    
    categories = {}
    for section in sections:
        cat = section.get('category', 'Unknown')
        categories[cat] = categories.get(cat, 0) + 1
    
    return {
        'total_sections': len(sections),
        'total_characters': total_chars,
        'total_pages': len(total_pages),
        'categories': categories,
        'avg_section_length': total_chars // len(sections) if sections else 0
    }

def main():
    print("=" * 60)
    print("ğŸ“„ ìµœì¢… JSON ìƒì„± (ë¬¸ë§¥ ì¸ì‹)")
    print("=" * 60)
    
    # í˜„ì¬ ì„¸ì…˜ ì •ë³´ ì½ê¸°
    session_file = BASE_DIR / "current_session.json"
    if not session_file.exists():
        print("âŒ í˜„ì¬ ì„¸ì…˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    with open(session_file, 'r', encoding='utf-8') as f:
        session_info = json.load(f)
    
    global CURRENT_SESSION_DIR
    CURRENT_SESSION_DIR = Path(session_info['session_dir'])
    
    # ëª¨ë“  í˜ì´ì§€ì˜ step6 ê²°ê³¼ ë¡œë“œ (ë¬¸ë§¥ ë³´ì¡´ìš©)
    print("ğŸ“‚ ëª¨ë“  í˜ì´ì§€ì˜ êµì • ê²°ê³¼ ë¡œë“œ ì¤‘...")
    all_pages_data = []
    
    # step6 ë””ë ‰í† ë¦¬ í™•ì¸
    step6_dir = CURRENT_SESSION_DIR / "step6_llm"
    if not step6_dir.exists():
        print(f"âŒ LLM êµì • ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {step6_dir}")
        return
    
    # intermediate JSON íŒŒì¼ ì‚¬ìš©
    intermediate_file = step6_dir / "llm_selected.json"
    if not intermediate_file.exists():
        print(f"âŒ LLM êµì • ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {intermediate_file}")
        return
    
    print(f"ğŸ“„ LLM êµì • ê²°ê³¼ ë¡œë“œ ì¤‘...")
    
    with open(intermediate_file, 'r', encoding='utf-8') as f:
        llm_data = json.load(f)
    
    print(f"   âœ… {len(llm_data.get('sections', []))}ê°œ ì„¹ì…˜ ë¡œë“œ ì™„ë£Œ")
    
    # llm_dataë¥¼ ê·¸ëŒ€ë¡œ ìµœì¢… JSONìœ¼ë¡œ ì‚¬ìš© (ì´ë¯¸ ì™„ì„±ëœ êµ¬ì¡°)
    print("ğŸ—ï¸ ìµœì¢… JSON ìƒì„±...")
    final_json = create_final_json(llm_data)
    
    # ë¬¸ë§¥ ì¸ì‹ JSON ìƒì„±
    print("ğŸ”— ë¬¸ë§¥ ì¸ì‹ JSON ìƒì„± ì¤‘...")
    
    # ëª¨ë“  í˜ì´ì§€ì˜ ë¸”ë¡ ë°ì´í„° ì¶”ì¶œ
    all_pages_blocks = []
    for page_data in all_pages_data:
        page_blocks = []
        for section in page_data.get('sections', []):
            for block in section.get('blocks', []):
                page_blocks.append(block)
        all_pages_blocks.append(page_blocks)
    
    # ë¬¸ë§¥ ì¸ì‹ JSON ìƒì„±
    context_aware_json = create_context_aware_json(all_pages_blocks)
    
    # ê²€ì¦
    print("ğŸ” JSON ê²€ì¦...")
    issues = validate_final_json(final_json)
    if issues:
        print("âš ï¸ ê²€ì¦ ì´ìŠˆ:")
        for issue in issues:
            print(f"   â€¢ {issue}")
    else:
        print("âœ… ê²€ì¦ í†µê³¼")
    
    # ìš”ì•½ ìƒì„±
    summary = generate_summary(final_json)
    
    # íŒŒì¼ ì €ì¥ (ì„¸ì…˜ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
    step7_dir = CURRENT_SESSION_DIR / "step7_final"
    step7_dir.mkdir(parents=True, exist_ok=True)
    
    document_id = final_json['document_id']
    output_file = step7_dir / f"{document_id}_final.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_json, f, ensure_ascii=False, indent=2)
    
    # ë¬¸ë§¥ ì¸ì‹ JSON ì €ì¥
    context_output_file = step7_dir / f"{document_id}_context_aware.json"
    with open(context_output_file, 'w', encoding='utf-8') as f:
        json.dump(context_aware_json, f, ensure_ascii=False, indent=2)
    
    # BGE-m3-ko ìµœì í™” JSON ìƒì„± (ë¬¸ë§¥ ë³´ì¡´)
    print(f"\nğŸ¤– BGE-m3-ko ìµœì í™” JSON ìƒì„± ì¤‘...")
    
    # ë¬¸ë§¥ ê·¸ë£¹ì„ BGE-m3-ko ìµœì í™” í˜•íƒœë¡œ ë³€í™˜
    bge_context_groups = create_bge_optimized_context_groups(context_aware_json)
    
    # í˜ì´ì§€ ë©”íƒ€ë°ì´í„°
    page_metadata = {
        "document_name": final_json.get("document_id", "unknown"),
        "page_number": final_json.get("page_number", 0),
        "timestamp": final_json.get("timestamp", "")
    }
    
    # ê¸°ì¡´ ë°©ì‹ BGE ìµœì í™”ë„ ìœ ì§€ (í˜¸í™˜ì„±)
    blocks_for_bge = []
    for section in final_json.get('sections', []):
        for block in section.get('blocks', []):
            blocks_for_bge.append({
                "bbox": block.get("bbox", [0, 0, 0, 0]),
                "category": block.get("category", "Text"),
                "text": block.get("text", ""),
                "confidence": block.get("confidence", 0.9)
            })
    
    bge_optimized_json = create_bge_optimized_json(blocks_for_bge, page_metadata)
    
    # ë¬¸ë§¥ ì¸ì‹ BGE ìµœì í™” JSON ìƒì„±
    context_bge_json = {
        "document_metadata": {
            "document_id": final_json.get("document_id", "unknown"),
            "total_pages": len(all_pages_data),
            "total_context_groups": len(bge_context_groups),
            "has_multi_page_tables": any(g["group_type"] == "table_continuation" for g in bge_context_groups),
            "language": "ko",
            "embedding_model": "dragonkue/bge-m3-ko"
        },
        "context_groups": bge_context_groups,
        "document_text": "\n".join([g["embedding_text"] for g in bge_context_groups]),
        "embedding_config": {
            "model_name": "dragonkue/bge-m3-ko",
            "embedding_dimension": 1024,
            "similarity_function": "cosine",
            "chunk_strategy": "context_aware",
            "max_chunk_tokens": 4000,
            "preserves_context": True,
            "handles_table_continuations": True
        }
    }
    
    # BGE ìµœì í™” JSON ì €ì¥
    bge_output_file = step7_dir / f"{document_id}_bge_optimized.json"
    with open(bge_output_file, 'w', encoding='utf-8') as f:
        json.dump(bge_optimized_json, f, ensure_ascii=False, indent=2)
    
    # ë¬¸ë§¥ ì¸ì‹ BGE ìµœì í™” JSON ì €ì¥
    context_bge_output_file = step7_dir / f"{document_id}_context_bge_optimized.json"
    with open(context_bge_output_file, 'w', encoding='utf-8') as f:
        json.dump(context_bge_json, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ‰ ìµœì¢… JSON ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ ì¼ë°˜ JSON: {output_file}")
    print(f"ğŸ“ ë¬¸ë§¥ ì¸ì‹ JSON: {context_output_file}")
    print(f"ğŸ“ BGE-m3-ko ìµœì í™” JSON: {bge_output_file}")
    print(f"ğŸ“ ë¬¸ë§¥ ì¸ì‹ BGE ìµœì í™” JSON: {context_bge_output_file}")
    
    print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
    print(f"   â€¢ ì´ ì„¹ì…˜: {summary['total_sections']}ê°œ")
    print(f"   â€¢ ì´ ë¬¸ì: {summary['total_characters']:,}ì")
    print(f"   â€¢ ì´ í˜ì´ì§€: {summary['total_pages']}í˜ì´ì§€")
    print(f"   â€¢ í‰ê·  ì„¹ì…˜ ê¸¸ì´: {summary['avg_section_length']}ì")
    
    if summary['categories']:
        print(f"   â€¢ ì¹´í…Œê³ ë¦¬ë³„:")
        for cat, count in summary['categories'].items():
            print(f"     - {cat}: {count}ê°œ")
    
    # ë¬¸ë§¥ ì¸ì‹ í†µê³„
    print(f"\nğŸ”— ë¬¸ë§¥ ì¸ì‹ í†µê³„:")
    print(f"   â€¢ ì´ í˜ì´ì§€: {len(all_pages_data)}ê°œ")
    print(f"   â€¢ ë¬¸ë§¥ ê·¸ë£¹: {len(bge_context_groups)}ê°œ")
    print(f"   â€¢ ë©€í‹°í˜ì´ì§€ í‘œ: {len([g for g in bge_context_groups if g['group_type'] == 'table_continuation'])}ê°œ")
    print(f"   â€¢ í˜ì´ì§€ ê°„ ì—°ê²°: {len(context_aware_json.get('cross_page_connections', []))}ê°œ")
    
    # BGE-m3-ko ìµœì í™” í†µê³„
    print(f"\nğŸ¤– BGE-m3-ko ìµœì í™” í†µê³„:")
    print(f"   â€¢ ì„ë² ë”© ê°€ëŠ¥ ë¸”ë¡: {len([b for b in bge_optimized_json['blocks'] if b['embedding_ready']])}ê°œ")
    print(f"   â€¢ ë¬¸ë§¥ ê·¸ë£¹ ì„ë² ë”©: {len([g for g in bge_context_groups if g['embedding_ready']])}ê°œ")
    if len(bge_optimized_json['blocks']) > 0:
        print(f"   â€¢ í‰ê·  í† í° ìˆ˜: {sum(b['token_estimate'] for b in bge_optimized_json['blocks']) / len(bge_optimized_json['blocks']):.1f}")
    print(f"   â€¢ ë¬¸ì„œ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(bge_optimized_json['document_text']):,}ì")
    print(f"   â€¢ ë¬¸ë§¥ ë³´ì¡´ ì—¬ë¶€: {'âœ…' if context_bge_json['embedding_config']['preserves_context'] else 'âŒ'}")
    print(f"   â€¢ í‘œ ì—°ì† ì²˜ë¦¬: {'âœ…' if context_bge_json['embedding_config']['handles_table_continuations'] else 'âŒ'}")
    
    # ìƒ˜í”Œ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°
    sections = final_json.get('sections', [])
    if sections:
        print(f"\nğŸ“‹ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 3ê°œ):")
        for i, section in enumerate(sections[:3]):
            title = section['title'][:40] + ('...' if len(section['title']) > 40 else '')
            text_preview = section['text_combined'][:80] + ('...' if len(section['text_combined']) > 80 else '')
            print(f"   {i+1}. [{section['id']}] {title}")
            print(f"      {text_preview}")

if __name__ == "__main__":
    main()
