#!/usr/bin/env python3
"""
â‘¥ ì´ì¤‘ OCR ë¹„êµ ë° LLM ì„ íƒ
ì…ë ¥: step1b_dual/combined.json (ì´ì¤‘ OCR ê²°ê³¼)
ì²˜ë¦¬: LLMì´ ë‘ OCR ê°’(ì›ë³¸/ì „ì²˜ë¦¬) ë¹„êµ + ë¬¸ë§¥ ê¸°ë°˜ìœ¼ë¡œ ìµœì  ê°’ ì„ íƒ
ì¶œë ¥: step6_llm/llm_selected.json
"""

import json
import requests
from pathlib import Path
from datetime import datetime
import time
import re

# ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
CURRENT_SESSION_DIR = None
EEVE_URL = "http://localhost:8003/v1/chat/completions"  # EEVE ì„œë²„

# Kiwi ì´ˆê¸°í™” (lazy loading)
kiwi = None
KIWI_AVAILABLE = False

def init_kiwi():
    """Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
    global kiwi, KIWI_AVAILABLE
    if kiwi is not None:
        return True
    
    try:
        from kiwipiepy import Kiwi
        kiwi = Kiwi()
        KIWI_AVAILABLE = True
        print("âœ… Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ë¡œë“œë¨")
        return True
    except Exception as e:
        KIWI_AVAILABLE = False
        print(f"âš ï¸ Kiwi ì‚¬ìš© ë¶ˆê°€: {e}")
        return False

# ì› ì•ˆì˜ í•œê¸€ ë¬¸ì â†’ ì› ì•ˆì˜ ìˆ«ì ë§¤í•‘
CIRCLED_HANGUL_TO_NUMBER = {
    'ã‰®': 'â‘ ',  # ê°€ â†’ 1
    'ã‰¯': 'â‘¡',  # ë‚˜ â†’ 2
    'ã‰°': 'â‘¢',  # ë‹¤ â†’ 3
    'ã‰±': 'â‘£',  # ë¼ â†’ 4
    'ã‰²': 'â‘¤',  # ë§ˆ â†’ 5
    'ã‰³': 'â‘¥',  # ë°” â†’ 6
    'ã‰´': 'â‘¦',  # ì‚¬ â†’ 7
    'ã‰µ': 'â‘§',  # ì•„ â†’ 8
    'ã‰¶': 'â‘¨',  # ì â†’ 9
    'ã‰·': 'â‘©',  # ì°¨ â†’ 10
    'ã‰¸': 'â‘ª',  # ì¹´ â†’ 11
    'ã‰¹': 'â‘«',  # íƒ€ â†’ 12
    'ã‰º': 'â‘¬',  # íŒŒ â†’ 13
    'ã‰»': 'â‘­',  # í•˜ â†’ 14
}

def normalize_circled_characters(text):
    """ì› ì•ˆì˜ í•œê¸€ ë¬¸ìë¥¼ ì› ì•ˆì˜ ìˆ«ìë¡œ ì •ê·œí™”"""
    if not text:
        return text
    
    for hangul, number in CIRCLED_HANGUL_TO_NUMBER.items():
        text = text.replace(hangul, number)
    
    return text

def calculate_kiwi_score(text):
    """Kiwi í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ í…ìŠ¤íŠ¸ì˜ ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜ ê³„ì‚°"""
    if not text or not KIWI_AVAILABLE:
        return 0.5  # ê¸°ë³¸ ì ìˆ˜
    
    try:
        # í˜•íƒœì†Œ ë¶„ì„
        result = kiwi.analyze(text)
        if not result or len(result) == 0:
            return 0.3
        
        tokens = result[0][0]  # ì²« ë²ˆì§¸ ë¶„ì„ ê²°ê³¼
        if not tokens:
            return 0.3
        
        total_tokens = len(tokens)
        if total_tokens == 0:
            return 0.3
        
        # 1. UNK(ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ì–´) ë¹„ìœ¨ ê³„ì‚°
        unk_count = sum(1 for token in tokens if token.tag == 'UNK' or token.tag == 'UNKNOWN')
        unk_ratio = unk_count / total_tokens
        
        # 2. ëª…ì‚¬/ë™ì‚¬/í˜•ìš©ì‚¬ ë¹„ìœ¨ (ì˜ë¯¸ ìˆëŠ” í’ˆì‚¬)
        meaningful_tags = ['NNG', 'NNP', 'NNB', 'VV', 'VA', 'MAG', 'MM']
        meaningful_count = sum(1 for token in tokens if token.tag in meaningful_tags)
        meaningful_ratio = meaningful_count / total_tokens
        
        # 3. ì ìˆ˜ ê³„ì‚° (ë†’ì„ìˆ˜ë¡ ìì—°ìŠ¤ëŸ¬ì›€)
        score = (1.0 - unk_ratio) * 0.7 + meaningful_ratio * 0.3
        
        return score
    except Exception as e:
        return 0.5


def apply_known_corrections(text):
    """ì•Œë ¤ì§„ OCR ì˜¤íƒ€ë¥¼ ìˆ˜ì •"""
    if not text:
        return text
    
    corrections = {
        'ì„ íœ´ìˆ˜ì¤€': 'ì„±ì·¨ìˆ˜ì¤€',
        'ë³´ì¥ë„ì‹œ': 'ë³´ì¥ì§€ë„', 
        'ë– ì‚°ì„': 'ë•ì‚°ì',
        'ê³ ìš©EKì •ì±…ì›': 'êµìœ¡ê³¼ì •í‰ê°€ì›',
        'ì²´ëª©': 'ì²´ìœ¡',
        'ê³ êµí•™ì •ì œ': 'ê³ êµí•™ì ì œ',
        'ì—°ê´€ë ¥ê´€': 'ì—°êµ¬í˜‘ë ¥ê´€',
        'ì¡°ê¸°íšŒ': 'ì¡°ê¸°í¬',
        'ì—° êµ¬ ì§„': 'ì—°êµ¬ì§„',
    }
    
    for wrong, correct in corrections.items():
        text = text.replace(wrong, correct)
    
    return text


def select_best_ocr_with_llm(ocr_raw, ocr_preprocessed, context_before="", context_after="", max_retries=2):
    """Kiwi í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ ë‘ OCR ê²°ê³¼ ì¤‘ ë” ë‚˜ì€ ê²ƒì„ ì„ íƒí•˜ê³  êµì •"""
    # ë¨¼ì € ì› ì•ˆì˜ í•œê¸€ ë¬¸ì ì •ê·œí™”
    ocr_raw = normalize_circled_characters(ocr_raw)
    ocr_preprocessed = normalize_circled_characters(ocr_preprocessed)
    
    # ë‘ ê°’ì´ ë™ì¼í•˜ê±°ë‚˜ í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ ê°„ë‹¨í•˜ê²Œ ì²˜ë¦¬
    if not ocr_raw and not ocr_preprocessed:
        return "", False, "both_empty"
    
    if not ocr_raw:
        return apply_known_corrections(ocr_preprocessed), False, "only_preprocessed"
    
    if not ocr_preprocessed:
        return apply_known_corrections(ocr_raw), False, "only_raw"
    
    if ocr_raw == ocr_preprocessed:
        return apply_known_corrections(ocr_raw), False, "same"
    
    # ë‘ ê°’ì´ ë‹¤ë¥¼ ë•Œ: Kiwi í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ ì„ íƒ
    len_raw = len(ocr_raw.strip())
    len_prep = len(ocr_preprocessed.strip())
    
    # ì „ì²˜ë¦¬ê°€ ë„ˆë¬´ ì´ìƒí•˜ë©´ ì›ë³¸ ì‚¬ìš©
    if len_prep < 3 or (len_raw > 10 and len_prep > len_raw * 3):
        return apply_known_corrections(ocr_raw), True, "kiwi_selected"
    
    # URL, ì´ë©”ì¼, ì „í™”ë²ˆí˜¸ê°€ í¬í•¨ëœ ê²½ìš° ì›ë³¸ ìš°ì„ 
    if any(pattern in ocr_raw for pattern in ['http://', 'https://', 'www.', '@', '043)', '02)']):
        # ì „ì²˜ë¦¬ì— ì´ëŸ° íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
        if not any(pattern in ocr_preprocessed for pattern in ['http://', 'https://', 'www.', '@']):
            return apply_known_corrections(ocr_raw), True, "kiwi_selected"
    
    # í•œìë‚˜ ì´ìƒí•œ ê¸°í˜¸ê°€ ë§ìœ¼ë©´ ë°°ì œ
    weird_chars = sum(1 for c in ocr_preprocessed if ord(c) > 0x4E00 and ord(c) < 0x9FFF)  # ì¤‘êµ­ì–´ í•œì
    if weird_chars > len_prep * 0.3:  # 30% ì´ìƒì´ í•œìë©´ ì´ìƒí•¨
        return apply_known_corrections(ocr_raw), True, "kiwi_selected"
    
    # Kiwië¡œ ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜ ê³„ì‚°
    score_raw = calculate_kiwi_score(ocr_raw)
    score_prep = calculate_kiwi_score(ocr_preprocessed)
    
    # ì ìˆ˜ ì°¨ì´ê°€ ëª…í™•í•˜ë©´ (0.15 ì´ìƒ) ë†’ì€ ìª½ ì„ íƒ
    if abs(score_raw - score_prep) > 0.15:
        if score_raw > score_prep:
            selected_text = ocr_raw
        else:
            selected_text = ocr_preprocessed
    else:
        # ì ìˆ˜ê°€ ë¹„ìŠ·í•˜ë©´ ê¸°ì¡´ ê·œì¹™ ì ìš©
        korean_ratio_raw = sum(1 for c in ocr_raw if '\uac00' <= c <= '\ud7a3') / max(len_raw, 1)
        korean_ratio_prep = sum(1 for c in ocr_preprocessed if '\uac00' <= c <= '\ud7a3') / max(len_prep, 1)
        
        # í•œê¸€ ë¹„ìœ¨ì´ ë” ë†’ì€ ê²ƒ ì„ íƒ
        if korean_ratio_prep > korean_ratio_raw * 1.2:
            selected_text = ocr_preprocessed
        elif korean_ratio_raw > korean_ratio_prep * 1.2:
            selected_text = ocr_raw
        # í•œê¸€ ë¹„ìœ¨ì´ ë¹„ìŠ·í•˜ë©´ ë” ê¸´ ê²ƒ ì„ íƒ
        elif len_prep > len_raw * 1.1:
            selected_text = ocr_preprocessed
        else:
            selected_text = ocr_raw
    
    return apply_known_corrections(selected_text), True, "kiwi_selected"

def process_blocks_with_dual_ocr(pages_data):
    """ë¸”ë¡ë³„ ì´ì¤‘ OCR ë¹„êµ ë° LLM ì„ íƒ"""
    # LLM ì„œë²„ í™•ì¸
    try:
        response = requests.get("http://localhost:8003/health", timeout=5)
        print("âœ… LLM ì„œë²„ ì—°ê²°ë¨")
    except:
        print("âŒ LLM ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ì›ë³¸ OCR ê²°ê³¼ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # LLM ì—†ì´ ì›ë³¸ ì‚¬ìš©
        for page in pages_data:
            for block in page.get('blocks', []):
                if 'ocr_raw' in block:
                    block['text'] = block['ocr_raw']
                    block['selection_method'] = 'raw_only'
        return pages_data
    
    total_blocks = 0
    total_changed = 0
    selection_stats = {
        'same': 0,
        'only_raw': 0,
        'only_preprocessed': 0,
        'llm_selected': 0,
        'llm_failed': 0
    }
    
    for page_idx, page in enumerate(pages_data, 1):
        page_num = page.get('page_number', page_idx)
        blocks = page.get('blocks', [])
        
        print(f"\nğŸ“„ í˜ì´ì§€ {page_num}: {len(blocks)}ê°œ ë¸”ë¡ ì²˜ë¦¬ ì¤‘...")
        
        for block_idx, block in enumerate(blocks):
            category = block.get('category', '').lower()
            
            # Picture/ImageëŠ” ê±´ë„ˆëœ€
            if category in ['picture', 'image']:
                block['text'] = ""
                block['selection_method'] = 'picture'
                continue
            
            ocr_raw = block.get('ocr_raw', '')
            ocr_preprocessed = block.get('ocr_preprocessed', '')
            
            # ë¬¸ë§¥ ì •ë³´ (ì´ì „/ì´í›„ ë¸”ë¡)
            context_before = ""
            context_after = ""
            
            if block_idx > 0:
                prev_block = blocks[block_idx - 1]
                context_before = prev_block.get('text', prev_block.get('ocr_raw', ''))[:50]
            
            if block_idx < len(blocks) - 1:
                next_block = blocks[block_idx + 1]
                context_after = next_block.get('text', next_block.get('ocr_raw', ''))[:50]
            
            # LLMìœ¼ë¡œ ìµœì  ê°’ ì„ íƒ
            selected_text, changed, method = select_best_ocr_with_llm(
                ocr_raw, ocr_preprocessed, context_before, context_after
            )
            
            block['text'] = selected_text
            block['selection_method'] = method
            
            selection_stats[method] = selection_stats.get(method, 0) + 1
            total_blocks += 1
            
            if changed:
                total_changed += 1
                print(f"    [{block_idx+1:03d}] {category:15s} âœï¸ ë³€ê²½: '{ocr_raw[:30]}...' â†’ '{selected_text[:30]}...' ({method})")
            else:
                print(f"    [{block_idx+1:03d}] {category:15s} â„¹ï¸ ìœ ì§€: '{selected_text[:30]}...' ({method})")
            
            # API ê³¼ë¶€í•˜ ë°©ì§€
            if method == 'llm_selected':
                time.sleep(1.5)
    
    print(f"\nğŸ“Š ì´ì¤‘ OCR ì„ íƒ í†µê³„:")
    print(f"   â€¢ ì´ ë¸”ë¡: {total_blocks}ê°œ")
    print(f"   â€¢ ë³€ê²½ë¨: {total_changed}ê°œ")
    print(f"   â€¢ ë™ì¼: {selection_stats.get('same', 0)}ê°œ")
    print(f"   â€¢ ì›ë³¸ë§Œ: {selection_stats.get('only_raw', 0)}ê°œ")
    print(f"   â€¢ ì „ì²˜ë¦¬ë§Œ: {selection_stats.get('only_preprocessed', 0)}ê°œ")
    print(f"   â€¢ Kiwi ì„ íƒ: {selection_stats.get('kiwi_selected', 0)}ê°œ")
    
    return pages_data

def main():
    print("=" * 60)
    print("ğŸ¤– Step 6: ì´ì¤‘ OCR ë¹„êµ ë° Kiwi ì„ íƒ")
    print("=" * 60)
    
    # Kiwi ì´ˆê¸°í™”
    init_kiwi()
    
    # í˜„ì¬ ì„¸ì…˜ ì •ë³´ ì½ê¸°
    session_file = BASE_DIR / "current_session.json"
    if not session_file.exists():
        print("âŒ í˜„ì¬ ì„¸ì…˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    with open(session_file, 'r', encoding='utf-8') as f:
        session_info = json.load(f)
    
    global CURRENT_SESSION_DIR
    CURRENT_SESSION_DIR = Path(session_info['session_dir'])
    
    # step1b ê²°ê³¼ íŒŒì¼ ë¡œë“œ (ì´ì¤‘ OCR ê²°ê³¼)
    step1b_dir = CURRENT_SESSION_DIR / "step1b_dual"
    combined_file = step1b_dir / "combined.json"
    
    if not combined_file.exists():
        print(f"âŒ step1b ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {combined_file}")
        print("   step1bë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    with open(combined_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    pages = data.get('pages', [])
    if not pages:
        print("âŒ í˜ì´ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“„ í˜ì´ì§€ ìˆ˜: {len(pages)}ê°œ")
    
    # ì´ì¤‘ OCR ë¹„êµ ë° LLM ì„ íƒ
    print("\nğŸ¤– ì´ì¤‘ OCR ë¹„êµ ë° LLM ì„ íƒ ì‹œì‘...")
    processed_pages = process_blocks_with_dual_ocr(pages)
    
    # ê²°ê³¼ ì €ì¥
    output_data = {
        "metadata": {
            "document_name": data.get('metadata', {}).get('document_name', 'unknown'),
            "total_pages": len(processed_pages),
            "pipeline_stage": "ì´ì¤‘ OCR ë¹„êµ ë° Kiwi ì„ íƒ",
            "timestamp": datetime.now().isoformat(),
            "selection_method": "Kiwi í˜•íƒœì†Œ ë¶„ì„ + ê·œì¹™ ê¸°ë°˜",
            "ocr_comparison": {
                "ocr_raw": "ì›ë³¸ ì´ë¯¸ì§€ OCR",
                "ocr_preprocessed": "ì „ì²˜ë¦¬ ì´ë¯¸ì§€ OCR",
                "selection": "Kiwi í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜ ê³„ì‚° í›„ ì„ íƒ"
            }
        },
        "pages": processed_pages
    }
    
    step6_dir = CURRENT_SESSION_DIR / "step6_llm"
    step6_dir.mkdir(parents=True, exist_ok=True)
    output_file = step6_dir / "llm_selected.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ‰ ì´ì¤‘ OCR ë¹„êµ ë° LLM ì„ íƒ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼: {output_file}")

if __name__ == "__main__":
    main()
